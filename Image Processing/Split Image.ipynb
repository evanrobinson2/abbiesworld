{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2acdd8c",
   "metadata": {},
   "source": [
    "<H1> save_objects(image_path, output_dir, minimumPixelCount)</H1>\n",
    "\n",
    "<h3>This is the first draft of the function that will take an image and convert it to subimages by trying to find contours using open CV.</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "352c46bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing at image_path: inputs/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0.png\n",
      ".. Found 24\n",
      "Received 24\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_0.png\" at i=0.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_1.png\" at i=1.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_2.png\" at i=2.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_3.png\" at i=3.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_4.png\" at i=4.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_5.png\" at i=5.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_6.png\" at i=6.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_7.png\" at i=7.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_8.png\" at i=8.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_9.png\" at i=9.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_10.png\" at i=10.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_11.png\" at i=11.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_12.png\" at i=12.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_13.png\" at i=13.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_14.png\" at i=14.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_15.png\" at i=15.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_16.png\" at i=16.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_17.png\" at i=17.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_18.png\" at i=18.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_19.png\" at i=19.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_20.png\" at i=20.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_21.png\" at i=21.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_22.png\" at i=22.\n",
      ".. Attempting to write \"output/carpetshark_16_digital_flat_stars_flat_appearance_metallic_col_80a8bcca-819b-4ede-a89c-6791de3c25e0_23.png\" at i=23.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(img):\n",
    "    \"\"\"\n",
    "    Preprocesses the image by converting to grayscale and applying Gaussian blur.\n",
    "    \n",
    "    Parameters:\n",
    "    img (numpy.ndarray): The input image.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The preprocessed image.\n",
    "    \"\"\"\n",
    "    # Check if the image has an alpha channel\n",
    "    if img.shape[2] == 3:\n",
    "        # If not, convert the image to RGBA\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    return blurred, img\n",
    "\n",
    "def apply_threshold(blurred):\n",
    "    \"\"\"\n",
    "    Applies Otsu's thresholding to the image.\n",
    "\n",
    "    Parameters:\n",
    "    blurred (numpy.ndarray): The preprocessed image.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The thresholded image.\n",
    "    \"\"\"\n",
    "    # Apply Otsu's thresholding\n",
    "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    return thresh\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_contours(thresh):\n",
    "    \"\"\"\n",
    "    Finds contours in the image.\n",
    "\n",
    "    Parameters:\n",
    "    thresh (numpy.ndarray): The thresholded image.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of contours.\n",
    "    ndarray: The hierarchical information.\n",
    "    \"\"\"\n",
    "    # Find contours\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    return contours, hierarchy\n",
    "\n",
    "def shrink_contour(contour, shrink_amount=3):\n",
    "    # Compute the bounding box for the contour\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    # Shrink the bounding rectangle by a certain amount\n",
    "    x += shrink_amount\n",
    "    y += shrink_amount\n",
    "    w -= 2 * shrink_amount\n",
    "    h -= 2 * shrink_amount\n",
    "\n",
    "    return x, y, w, h\n",
    "\n",
    "def feather_mask(mask, feather_amount=3):\n",
    "    # Blur the mask to create a \"feather\" effect\n",
    "    return cv2.GaussianBlur(mask, (feather_amount, feather_amount), 0)\n",
    "\n",
    "def extract_objects(img, contours, hierarchy, minimumPixelCount):\n",
    "    \"\"\"\n",
    "    Extracts objects from the image based on contours.\n",
    "\n",
    "    Parameters:\n",
    "    img (numpy.ndarray): The input image.\n",
    "    contours (list): A list of contours.\n",
    "    hierarchy (ndarray): The hierarchical information.\n",
    "    minimumPixelCount (int): The minimum number of pixels an object should have.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of extracted objects.\n",
    "    \"\"\"\n",
    "    objects = []\n",
    "    \n",
    "    # Iterate over the contours\n",
    "    for i, contour in enumerate(contours):\n",
    "        # Calculate actual contour area\n",
    "        contourArea = cv2.contourArea(contour)\n",
    "        \n",
    "        # Check if the contour area is at least as large as minimumPixelCount\n",
    "        if contourArea >= minimumPixelCount:\n",
    "          \n",
    "            # Shrink the contour\n",
    "            x, y, w, h = shrink_contour(contour)\n",
    "\n",
    "            # Extract the object and save it to a file\n",
    "            obj = img[y:y+h, x:x+w].copy()\n",
    "\n",
    "            # Create a mask and draw the contour on it\n",
    "            mask = np.zeros((h, w), dtype=np.uint8)\n",
    "            cv2.drawContours(mask, [contour], -1, (255), thickness=cv2.FILLED, offset=(-x, -y))\n",
    "\n",
    "            # Feather the mask\n",
    "            mask = feather_mask(mask)\n",
    "\n",
    "            # Apply the mask to the alpha channel of the object, making the area outside the contour transparent\n",
    "            obj[..., 3] = mask\n",
    "            \n",
    "            # Get the hierarchy level of the current contour\n",
    "            hierarchy_level = hierarchy[0, i, 3]\n",
    "            \n",
    "            objects.append(obj)\n",
    "    \n",
    "    return objects\n",
    "\n",
    "def process_image(image_path, minimumPixelCount):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    print(f\"Processing at image_path: {image_path}\")\n",
    "    \n",
    "    # Preprocess the image\n",
    "    blurred, img = preprocess_image(img)\n",
    "    \n",
    "    # Apply threshold\n",
    "    thresh = apply_threshold(blurred)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, hierarchy = find_contours(thresh)\n",
    "    \n",
    "    # Extract objects\n",
    "    objects = extract_objects(img, contours, hierarchy, minimumPixelCount)\n",
    "    print(f\".. Found {len(objects)}\")    \n",
    "    return objects  # Return only the list of objects\n",
    "\n",
    "def process_images_in_folder(input_dir, output_dir, min_pixel_count=50*50):\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(input_dir)\n",
    "\n",
    "    # Loop through each file\n",
    "    for file in files:\n",
    "        # Check if the file is a PNG image\n",
    "        if file.endswith(\".png\"):\n",
    "            # Construct the full image path\n",
    "            image_path = os.path.join(input_dir, file)\n",
    "\n",
    "            # Process the image\n",
    "            processed_images = process_image(image_path, min_pixel_count)\n",
    "            print(f\"Received {len(processed_images)}\")\n",
    "            # Save each processed image\n",
    "            for i, image in enumerate(processed_images):\n",
    "                # Construct the output file path\n",
    "                output_path = os.path.join(output_dir, f'{os.path.splitext(file)[0]}_{i}.png')\n",
    "\n",
    "                print(f'.. Attempting to write \"{output_path}\" at i={i}.')\n",
    "                \n",
    "                # Save the image\n",
    "                cv2.imwrite(output_path, image)\n",
    "                \n",
    "                \n",
    "# input folder = \"./inputs/\" <- need to exclude non .png files\n",
    "# output folder = \"./outputs/\"\n",
    "\n",
    "input_dir =\"inputs\"\n",
    "output_dir = \"output\"\n",
    "\n",
    "process_images_in_folder(input_dir, output_dir, min_pixel_count=50*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9985dae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
